% !TeX spellcheck = en_GB
\chapter{Temporal Tuning}
\label{chp:temporal_tuning}

\vspace{20pt}

\begin{OpeningQuote}
Complex effects, such as representing visual motion, are the outcome of the dynamics of neural networks. This means that while network properties are dependent on the properties of the neurons in the network, they are nevertheless not identical to cellular properties, nor to \emph{simple} combinations of cellular properties. Interactions of neurons in networks is required for complex effects, but it is dynamical, not a simple wind-up doll affair.
\OpeningQuoteSource{Particia S. Churchland and Terrence J. Sejnowski}{The Computational Brain (1992)}
\end{OpeningQuote}

\begin{PriorPublication}
Some of the material in this chapter has previously been published in the form of two technical reports, namely \citet{stockel2021constructing}, where we derive feedback matrices for polynomial temporal basis functions, and \citet{stockel2021discrete}, where we systematically compare different temporal function bases.
\end{PriorPublication}

\begin{Contributions}
This chapter has in part been inspired by Volker and Eliasmith's work on the Legendre Delay Network (\LDN) and integrating higher-order synapses into the \NEF \citep{voelker2018improving,voelker2019}, as well as Chilkuri and Eliasmith's effort on efficiently training deep neural networks that utilise the Legendre Delay Network \citep{chilkuri2021parallelizing}.
Novel work in this chapter includes generalising the third \NEF principle to take temporal tuning into account, as well as demonstrating that it is possible to build networks that fulfil desired temporal tuning in networks with heterogeneous synaptic filters by solving a linear least-squares optimisation problem.
Furthermore, we formalise the notion of \LTI systems approximating sliding-window transformations and suggest the \enquote{information erasure} method for establishing a rectangle window.
We use these ideas for an alternative derivation of the \LDN \LTI system from first principles and propose a similar \LTI system that generates a \enquote{modified Fourier basis}.
We show that this modified Fourier basis often outperforms the \LDN \LTI and has more favourable computational properties under Runge-Kutta integration.
\end{Contributions}

\clearpage
\input{content/chapters/04_temporal_tuning/04_00_introduction}

\clearpage
\setcounter{section}{0}
\input{content/chapters/04_temporal_tuning/04_01_temporal_tuning}

\clearpage
\setcounter{section}{1}
\input{content/chapters/04_temporal_tuning/04_02_temporal_basis_functions}

\clearpage
\setcounter{section}{2}
\input{content/chapters/04_temporal_tuning/04_03_weight_solving}

\clearpage
\setcounter{section}{3}
\input{content/chapters/04_temporal_tuning/04_04_applications_to_ml}

\clearpage
\setcounter{section}{4}
\input{content/chapters/04_temporal_tuning/04_05_conclusion}
